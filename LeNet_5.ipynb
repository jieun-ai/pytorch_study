{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms # 이미지 변환(전처리) 기능을 제공\n",
    "from torch.autograd import Variable\n",
    "from torch import optim # 경사하강법을 이용하여 가중치를 구하기 위한 옵티마이저\n",
    "import os # 파일 경로에 대한 함수들을 제공\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm # 진행 상황 표현\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 이미지 데이터셋 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():    \n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.data_transform = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]), ## 1\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def __call__(self, img, phase): ## 2\n",
    "        return self.data_transform[phase](img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 이미지 데이터셋을 불러온 후 훈련, 검증, 테스트로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 92 10\n"
     ]
    }
   ],
   "source": [
    "cat_directory = './dogs-vs-cats/Cat/'\n",
    "dog_directory = './dogs-vs-cats/Dog/'\n",
    "\n",
    "## 1\n",
    "cat_images_filepaths = sorted([os.path.join(cat_directory, f) \n",
    "                               for f in os.listdir(cat_directory)])   \n",
    "dog_images_filepaths = sorted([os.path.join(dog_directory, f) \n",
    "                               for f in os.listdir(dog_directory)])\n",
    "                               \n",
    "## 2                               \n",
    "images_filepaths = [*cat_images_filepaths, *dog_images_filepaths] \n",
    "\n",
    "## 3\n",
    "correct_images_filepaths = [i for i in images_filepaths if cv2.imread(i) is not None]    \n",
    "\n",
    "random.seed(42) ## 4\n",
    "random.shuffle(correct_images_filepaths)\n",
    "\n",
    "# 일부 데이터만 사용\n",
    "train_images_filepaths = correct_images_filepaths[:400]    \n",
    "val_images_filepaths = correct_images_filepaths[400:-10]  \n",
    "test_images_filepaths = correct_images_filepaths[-10:]    \n",
    "\n",
    "print(len(train_images_filepaths), len(val_images_filepaths), len(test_images_filepaths))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. test 데이터셋 이미지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def display_image_grid(images_filepaths, predicted_labels=(), cols=5):\n",
    "    rows = len(images_filepaths) // cols  \n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(12, 6))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    for i, image_filepath in enumerate(images_filepaths): # 경로를 정규화 함\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) ## 1\n",
    "        \n",
    "        true_label = os.path.normpath(image_filepath).split(os.sep)[-2] ## 2\n",
    "        predicted_label = predicted_labels[i] if predicted_labels else true_label ## 3\n",
    "        color = \"green\" if true_label == predicted_label else \"red\"\n",
    "\n",
    "        ax[i].imshow(image)\n",
    "        ax[i].set_title(predicted_label, color=color)\n",
    "        ax[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 이미지 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogvsCatDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None, phase='train'):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform # DogvsCatDataset 클래스를 호출할 때 transform에 대한 매개변수를 받아 옵니다.\n",
    "        self.phase = phase # train 적용\n",
    "\n",
    "    def __len__(self): # images_filepaths 데이터셋의 전체 길이 반환\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self,idx): # 데이터셋에서 데이터를 가져오는 부분으로 결과는 텐서 형태 \n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path) # img_path 위치에서 이미지 데이터들을 가져옴\n",
    "        img_transformed = self.transform(img, self.phase) # 이미지에 'train' 전처리 적용\n",
    "        label = img_path.split('/')[-1].split('.')[0] ## 1\n",
    "\n",
    "        if label == 'dog':\n",
    "            label = 1\n",
    "        elif label == 'cat':\n",
    "            label = 0\n",
    "        return img_transformed, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 변수 값 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 이미지 데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DogvsCatDataset(train_images_filepaths, \n",
    "                                transform=ImageTransform(size,mean, std), \n",
    "                                phase='train') # train 이미지에 train_transforms를 적용\n",
    "val_dataset = DogvsCatDataset(val_images_filepaths, \n",
    "                              transform=ImageTransform(size,mean, std), \n",
    "                              phase='val') # val 이미지에 train_transforms를 적용\n",
    "\n",
    "index = 0\n",
    "print(train_dataset.__getitem__(index)[0].size()) # 훈련 데이터 train_dataset.__getitem__[0][0]의 크기(size) 출력\n",
    "print(train_dataset.__getitem__(index)[1]) # 훈련 데이터의 레이블 출력"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 데이터로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True) ## 1\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# train_dataloader와 val_dataloader를 합쳐서 표현\n",
    "dataloader_dict = {'train': train_dataloader, 'val': val_dataloader}\n",
    "\n",
    "batch_iterator = iter(train_dataloader)\n",
    "inputs, label = next(batch_iterator)\n",
    "print(inputs.size())\n",
    "print(label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. 모델의 네트워크 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        # 입력 : (3,244,244) 출력 : (16,220,220)\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=5, stride=1, padding=0) \n",
    "        self.relu1 = nn.ReLU() \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) # 220/2 -> (16,110,110)\n",
    "        \n",
    "        # 입력 : (16,110,110) 출력 : (32,106,106)\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0) \n",
    "        self.relu2 = nn.ReLU() # activation\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2) # 110/2 -> (32,53,53)   \n",
    "        \n",
    "        self.fc1 = nn.Linear(32*53*53, 512) \n",
    "        self.relu5 = nn.ReLU()         \n",
    "        self.fc2 = nn.Linear(512, 2) \n",
    "        self.output = nn.Softmax(dim=1)        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.cnn1(x) \n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out) \n",
    "        out = self.relu2(out) \n",
    "        out = self.maxpool2(out) \n",
    "        out = out.view(out.size(0), -1) # 완결연결층에 데이터를 전달하기 위해 데이터 형태를 1차원으로 바꿉니다.\n",
    "        out = self.fc1(out) \n",
    "        out = self.fc2(out)                    \n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. 모델 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (cnn1): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (cnn2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=89888, out_features=512, bias=True)\n",
      "  (relu5): ReLU()\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      "  (output): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. torchsummary 라이브러리를 이용한 모델의 네트워크 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 220, 220]           1,216\n",
      "              ReLU-2         [-1, 16, 220, 220]               0\n",
      "         MaxPool2d-3         [-1, 16, 110, 110]               0\n",
      "            Conv2d-4         [-1, 32, 106, 106]          12,832\n",
      "              ReLU-5         [-1, 32, 106, 106]               0\n",
      "         MaxPool2d-6           [-1, 32, 53, 53]               0\n",
      "            Linear-7                  [-1, 512]      46,023,168\n",
      "            Linear-8                    [-1, 2]           1,026\n",
      "           Softmax-9                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 46,038,242\n",
      "Trainable params: 46,038,242\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 19.47\n",
      "Params size (MB): 175.62\n",
      "Estimated Total Size (MB): 195.67\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. 옵티마이저와 손실 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. 모델의 파라미터와 손실 함수를 CPU에 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. 모델 학습 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader_dict, criterion, optimizer, num_epoch):    \n",
    "    since = time.time()\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epoch))\n",
    "        print('-'*20)\n",
    "        \n",
    "        for phase in ['train', 'val']:           \n",
    "            if phase == 'train':\n",
    "                model.train() # 모델을 학습시키겠다는 의미\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            \n",
    "            for inputs, labels in tqdm(dataloader_dict[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                    epoch_loss += loss.item() * inputs.size(0)\n",
    "                    epoch_corrects += torch.sum(preds == labels.data)\n",
    "                    \n",
    "            epoch_loss = epoch_loss / len(dataloader_dict[phase].dataset)\n",
    "            epoch_acc = epoch_corrects.double() / len(dataloader_dict[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/_bp5b7pn22q6_9bvlv0wq_kc0000gp/T/ipykernel_2522/1654274113.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for inputs, labels in tqdm(dataloader_dict[phase]):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e453d302602a4547bdc987caecda4f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6940 Acc: 0.5250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51eba082ca6c42679ac522ecb2eb08a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7253 Acc: 0.4674\n",
      "Epoch 2/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cbf40c51914fd0a1f00ef2aec26741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6936 Acc: 0.5175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "167c796fddac420f99230bbf9b996f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7053 Acc: 0.5000\n",
      "Epoch 3/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8941fc6840c34a09b176055d8bd8a06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6811 Acc: 0.5500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0559e2e98d0b4e1f9e48551dbbfd4447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7309 Acc: 0.4348\n",
      "Epoch 4/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51331a66181a4251bbe279650ab879de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6819 Acc: 0.5800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07e5e17d89d400e8503c572824e9938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7057 Acc: 0.5326\n",
      "Epoch 5/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03fddba7a074fde85a95a191a5197a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6738 Acc: 0.5875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0413636847bb4d5997dd03673845900f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6990 Acc: 0.5217\n",
      "Epoch 6/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96be77e119714681a967658e1cb6c177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6744 Acc: 0.5525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c429b797f841699b7b9268e2db63a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.7218 Acc: 0.4674\n",
      "Epoch 7/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15549eefd7934c16b97ee209a1062513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6758 Acc: 0.5650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6178e7ffa1a45468500db12f2be6254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6848 Acc: 0.5109\n",
      "Epoch 8/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef6e421f9af4d17a9cfd2793f328bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6627 Acc: 0.6125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8e7174049644bb80aa1fccd9a606a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6821 Acc: 0.5543\n",
      "Epoch 9/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c866f50a064915b9f42e39027e5ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6672 Acc: 0.6325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb4465ad7ac46ebaae1ae39468d4c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6834 Acc: 0.5652\n",
      "Epoch 10/10\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed58e0bb22a4e4aa791b267f5abd1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6567 Acc: 0.6150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef113d18f5f47da97053fd7e294e0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6806 Acc: 0.5761\n",
      "Training complete in 2m 16s\n",
      "Best val Acc: 0.576087\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 10\n",
    "model = train_model(model, dataloader_dict, criterion, optimizer, num_epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. 모델 테스트를 위한 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l1/_bp5b7pn22q6_9bvlv0wq_kc0000gp/T/ipykernel_2522/849688909.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for test_path in tqdm(test_images_filepaths): # test 데이터셋 이용\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e81d667b5524bae973f3393583e796e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "id_list = []\n",
    "pred_list = []\n",
    "_id=0\n",
    "\n",
    "# 역전파 중 텐서들에 대한 변화도를 계산할 필요가 없음을 나타내는 것으로, 훈련 데이터셋의 모델 학습과 가장 큰 차이점입니다.\n",
    "with torch.no_grad(): \n",
    "    for test_path in tqdm(test_images_filepaths): # test 데이터셋 이용\n",
    "        img = Image.open(test_path)\n",
    "        _id =test_path.split('/')[-1].split('.')[1]\n",
    "        transform = ImageTransform(size, mean, std)\n",
    "        img = transform(img, phase='val') # test 데이터셋 전처리\n",
    "        img = img.unsqueeze(0) ## 1\n",
    "        img = img.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        outputs = model(img)\n",
    "        preds = F.softmax(outputs, dim=1)[:, 1].tolist() ## 2       \n",
    "        id_list.append(_id)\n",
    "        pred_list.append(preds[0])\n",
    "       \n",
    "res = pd.DataFrame({\n",
    "    'id': id_list,\n",
    "    'label': pred_list\n",
    "}) # test 예측 결과인 Id와 레이블을 데이터 프레임에 저장\n",
    "\n",
    "res.sort_values(by='id', inplace=True)\n",
    "res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "res.to_csv('LeNet.csv', index=False) # 데이터프레임을 csv 파일로 저장"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. 테스트 데이터셋의 예측 결과 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>0.424191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>0.458853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.636709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162</td>\n",
       "      <td>0.498484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>167</td>\n",
       "      <td>0.531948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.378861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>210</td>\n",
       "      <td>0.569178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>211</td>\n",
       "      <td>0.552809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>213</td>\n",
       "      <td>0.397481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>224</td>\n",
       "      <td>0.573105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id     label\n",
       "0  109  0.424191\n",
       "1  145  0.458853\n",
       "2   15  0.636709\n",
       "3  162  0.498484\n",
       "4  167  0.531948\n",
       "5  200  0.378861\n",
       "6  210  0.569178\n",
       "7  211  0.552809\n",
       "8  213  0.397481\n",
       "9  224  0.573105"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3811",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
